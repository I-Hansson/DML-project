{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b3f98896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import GPT2Tokenizer\n",
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "24726d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/isachansson/DML-project/notebooks/models/finetuned_distilgpt2_with_tokens.pt\n"
     ]
    }
   ],
   "source": [
    "model_path = Path.cwd() / \"models\" / \"finetuned_distilgpt2_with_tokens.pt\"\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fa404d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model_name = \"distilgpt2\"\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd476c7",
   "metadata": {},
   "source": [
    "## Get genereated songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f9885b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Heavy Metal': '[Heavy Metal] Generate Heavy Metal lyrics.\\n\\n\\n[Solo: P. Wagner, R. Schmidt]\\n\\n[Solo: M. Weikal/Lyrics: E. Holopainen - S. Hanneman & D. van Goghling]',\n",
       " 'Pop': \"[POP] Generate Pop lyrics.\\n\\n\\n\\nWhen you're with me I'm always on the same page\\nThere's a message that we all can see through\\nSo take care of it, and be aware\\nOf your life when there's no one else around\\nYou know how to run away from what hurts\\nWe'll make love tonight for our children\\nBut don't let them go again (oh, yeah)\\nI won 'cause they will!\\n\\nOhh ohh ohh ohh ohh ohh ohhh, ohh ohh, ohh ohh ohh ohh, ohh ohh, ohh ohh...\\nAnd now my heart is beating like a drum, cause nothing but pain starts to break\\nCause everything\",\n",
       " 'Indie': '[Indie] Generate Indie lyrics for the magazine, \"Nashville\"\\n\\nWell I\\'m gonna make some noise tonight - uh oh\\nCause you can\\'t hear my voice when I speak my mind.\\nIt\\'s such a good time and everybody around is here watching us talk.\\n\\nI hope that it donÂ´t feel so bad this morning.\\n\\'Cause we know how to do things right but not at all.\\nAnd people are saying that our love was just a game of fooling ourselves. (yeah)\\nWhen the night comes down cause we\\'ve got nothing on the line.\\nAnd now there is no way to go where your heart belongs.\\nBut if you want to come along with me please call out your name:\\n\\'cause'}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = [\"[Heavy Metal] Generate Heavy Metal lyrics\", \"[Indie] Generate Indie lyrics\",\"[POP] Generate Pop lyrics\"]\n",
    "genres = ['Heavy Metal', 'Indie', 'Pop']\n",
    "genreated_songs = {\n",
    "    'Heavy Metal' : '',\n",
    "    'Pop' : '',\n",
    "    'Indie' : ''\n",
    "}\n",
    "for prompt, genre in zip(prompts, genres):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            do_sample=True,\n",
    "            max_new_tokens=150,\n",
    "            top_p=0.9,\n",
    "            top_k=40,\n",
    "            temperature=0.8,\n",
    "            repetition_penalty=1.2,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            num_return_sequences=1,\n",
    "        )\n",
    "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    genreated_songs[genre] = text\n",
    "\n",
    "genreated_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ddfb9b",
   "metadata": {},
   "source": [
    "### Geta  random song from the data one for each genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c83ff016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre\n",
      "Heavy Metal    13378\n",
      "Pop            13128\n",
      "Indie          12909\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(os.getcwd()).parent / 'data'\n",
    "\n",
    "df = pd.read_csv(f'{data_path}/lyrics_filtered_768tokens.csv')\n",
    "\n",
    "print(df['genre'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b04f97ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Pop  Indie  Heavy Metal\n",
      "Gen Pop          0.642  0.340       -0.053\n",
      "Gen Indie        0.574  0.269       -0.129\n",
      "Gen Heavy Metal  0.210  0.384        0.611\n"
     ]
    }
   ],
   "source": [
    "prompts = [\"[Heavy Metal] \", \"[Indie] \",\"[POP]\"]\n",
    "genres = ['Heavy Metal', 'Indie', 'Pop']\n",
    "genreated_songs = {\n",
    "    'Heavy Metal' : '',\n",
    "    'Pop' : '',\n",
    "    'Indie' : ''\n",
    "}\n",
    "for prompt, genre in zip(prompts, genres):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        with torch.inference_mode():\n",
    "            outputs = model.generate(\n",
    "            input_ids,\n",
    "            do_sample=True,\n",
    "            max_new_tokens=150,\n",
    "            top_p=0.9,\n",
    "            top_k=40,\n",
    "            temperature=1.0,\n",
    "            repetition_penalty=1.1,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            num_return_sequences=1,\n",
    "        )\n",
    "        text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        genreated_songs[genre] = text\n",
    "\n",
    "genreated_songs\n",
    "sampled_real_songs = {}\n",
    "\n",
    "for genre in ['Pop', 'Indie', 'Heavy Metal']:\n",
    "    subset = df[df['genre'] == genre]\n",
    "    samples = subset.sample(50, random_state=6)\n",
    "    sampled_real_songs[genre] = samples['lyrics'].tolist()\n",
    "    \n",
    "from torch.nn.functional import cosine_similarity\n",
    "def get_hidden_representation(text: str, model, tokenizer, device=\"cpu\"):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, \n",
    "                      max_length=768, padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        last_hidden = outputs.hidden_states[-1]\n",
    "\n",
    "        mask = inputs[\"attention_mask\"].unsqueeze(-1)\n",
    "        sentence_vec = (last_hidden * mask).sum(1) / mask.sum(1).clamp(min=1e-9)\n",
    "    return sentence_vec\n",
    "\n",
    "genres = ['Pop', 'Indie', 'Heavy Metal']\n",
    "\n",
    "similarity_matrix = np.zeros((len(genres), len(genres)))\n",
    "\n",
    "for i, gen_g in enumerate(genres):\n",
    "    v_gen = get_hidden_representation(genreated_songs[gen_g], model, tokenizer, device)\n",
    "    \n",
    "    for j, real_g in enumerate(genres):\n",
    "        sims = []\n",
    "        for real_song in sampled_real_songs[real_g]:\n",
    "            v_real = get_hidden_representation(real_song, model, tokenizer, device)\n",
    "            sim = cosine_similarity(v_gen, v_real, dim=1).item()\n",
    "            sims.append(sim)\n",
    "        similarity_matrix[i, j] = np.mean(sims)\n",
    "\n",
    "df_sim = pd.DataFrame(similarity_matrix, index=[f\"Gen {g}\" for g in genres], columns=genres)\n",
    "\n",
    "print(df_sim.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dbe6af2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¬ Semantic similarity matrix (SentenceTransformer):\n",
      "                   Pop  Indie  Heavy Metal\n",
      "Gen Pop          0.356  0.294        0.255\n",
      "Gen Indie        0.307  0.264        0.250\n",
      "Gen Heavy Metal  0.284  0.306        0.371\n"
     ]
    }
   ],
   "source": [
    "prompts = [\"[Heavy Metal] \", \"[Indie] \",\"[POP]\"]\n",
    "genres = ['Heavy Metal', 'Indie', 'Pop']\n",
    "genreated_songs = {\n",
    "    'Heavy Metal' : '',\n",
    "    'Pop' : '',\n",
    "    'Indie' : ''\n",
    "}\n",
    "for prompt, genre in zip(prompts, genres):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        with torch.inference_mode():\n",
    "            outputs = model.generate(\n",
    "            input_ids,\n",
    "            do_sample=True,\n",
    "            max_new_tokens=150,\n",
    "            top_p=0.9,\n",
    "            top_k=40,\n",
    "            temperature=1.0,\n",
    "            repetition_penalty=1.1,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            num_return_sequences=1,\n",
    "        )\n",
    "        text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        genreated_songs[genre] = text\n",
    "\n",
    "genreated_songs\n",
    "sampled_real_songs = {}\n",
    "\n",
    "for genre in ['Pop', 'Indie', 'Heavy Metal']:\n",
    "    subset = df[df['genre'] == genre]\n",
    "    samples = subset.sample(50, random_state=6)\n",
    "    sampled_real_songs[genre] = samples['lyrics'].tolist()\n",
    "    \n",
    "# --- Semantic comparison version ---\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "# Load pretrained semantic embedding model\n",
    "semantic_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "genres = ['Pop', 'Indie', 'Heavy Metal']\n",
    "semantic_sim_matrix = np.zeros((len(genres), len(genres)))\n",
    "\n",
    "for i, gen_g in enumerate(genres):\n",
    "\n",
    "    v_gen = torch.tensor(semantic_model.encode(genreated_songs[gen_g], convert_to_numpy=True))\n",
    "    v_gen = v_gen.unsqueeze(0)  \n",
    "    \n",
    "    for j, real_g in enumerate(genres):\n",
    "        sims = []\n",
    "        for real_song in sampled_real_songs[real_g]:\n",
    "            v_real = torch.tensor(semantic_model.encode(real_song, convert_to_numpy=True))\n",
    "            v_real = v_real.unsqueeze(0)\n",
    "            sim = cosine_similarity(v_gen, v_real, dim=1).item()\n",
    "            sims.append(sim)\n",
    "        semantic_sim_matrix[i, j] = np.mean(sims)\n",
    "\n",
    "\n",
    "df_sem = pd.DataFrame(semantic_sim_matrix, index=[f\"Gen {g}\" for g in genres], columns=genres)\n",
    "print(\"\\nðŸ’¬ Semantic similarity matrix (SentenceTransformer):\")\n",
    "print(df_sem.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4af095b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['genre', 'lyrics', 'token_count', 'formatted_text']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "341c48d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Heavy Metal] Ã‚\n",
      "\n",
      "In the dark I see the future and I think about it)\n",
      "I am the one that can save you, to save me\n",
      "\n",
      "And if this is our end, would we just die in fear?\n",
      "If this is our end, should we have the chance to stop the madness?\n",
      "What a wonderful world!\n",
      "\n",
      "No more killing, no more killing, no more living hell, yeah\n",
      "\n",
      "I am the one that will save your life\n",
      "From your fear of dying, from your fears of dying\n",
      "\n",
      "So let me give you my heart\n",
      "My love, my life\n",
      "I will not die again\n",
      "\n",
      "And what's happening now, do you believe it?\n",
      "The world is changing, but don't\n",
      "[POP]\n",
      "I got a long list of reasons, why)\n",
      "I've been getting older (yeah), my heart's getting too fast\n",
      "I've been feeling down and down again (yeah), I'm getting younger\n",
      "(oh, oh, oh, oh)\n",
      "I don't want you (no, no)\n",
      "(I don't want you)\n",
      "I don't want you (no, no)\n",
      "\n",
      "\n",
      "(No-one could ever understand)\n",
      "Why did I have to do it like this?\n",
      "It's hard to see the future in me, yeah...\n",
      "And there's so many things that must change (to be different)\n",
      "So much more than the past (to be different)\n",
      "I hope we'll find love\n",
      "[Indie]!!!!!!!!!!!!!!\n",
      "\n",
      "Boys in the crowd, no need to hear them\n",
      "But boy what they gotta do\n",
      "They ain't got a reason for their actions\n",
      "If they didn't stop and act like a fool\n",
      "There'd be nothing left of us\n",
      "Just because we can't stand 'em all out\n",
      "When the lights go down it feels right\n",
      "The music hits, it sounds so good\n",
      "It makes me wanna know if I'm still alive\n",
      "I wanna know if I'm still alive\n",
      "I wanna know if I'm still alive\n",
      "\n",
      "Hey, let's dance!\n",
      "Let's run away from this bad life\n",
      "With our voices in the streets\n",
      "We can't hide ourselves from each other\n",
      "And now everything's quiet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for value in genreated_songs.values():\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c26bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
