{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f61e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac58782e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/isachansson/DML-project/notebooks/models/last_training.pt\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilgpt2\"\n",
    "model_save_path = Path(os.getcwd()) / 'models'\n",
    "weights_path = f'{model_save_path}/last_training.pt'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(weights_path)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40641bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model.load_state_dict(torch.load(weights_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b20bc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAMPLE 1\n",
      "============================================================\n",
      "Genre: Heavy Metal\n",
      "\n",
      "Lyrics:\n",
      "The sun is cold, but it's not like the summer in my world\n",
      "There's no moon to see you through, nothing of the earth left behind\n",
      "I've been waiting all night long for you\n",
      "I can't wait to get closer, I'm on your way\n",
      "Just another day away from what we did before\n",
      "But if things don' feel right now\n",
      "Or do I just go home?\n",
      "It seems time has come to make a difference\n",
      "Time has come to stop us, and there's something about life inside\n",
      "In this moment that they'll take care of me\n",
      "And when love will end again\n",
      "And at peace will come true!\n",
      "\n",
      "We're going somewhere - nowhere between us\n",
      "A lot has changed since we came together\n",
      "Our story told the story of our love, their times were different\n",
      "But still it feels so old today\n",
      "When we are alone with you\n",
      "You won't have to leave until we change the ways of life\n",
      "As though we used to be strangers\n",
      "To keep ourselves apart without losing our place\n",
      "Love may start turning up in the morning\n",
      "All around you might wonder why\n",
      "Is someone here who makes her happy enough to walk by me\n",
      "Now that she's gone, then maybe even more needs to know\n",
      "That love means too much tonight\n",
      "For whatever reason or because he wants it back\n",
      "He doesn´t need to worry anymore\n",
      "Cause every time I wake him, let´s talk.\n",
      "Oh, yeah.\n",
      "\n",
      "============================================================\n",
      "SAMPLE 2\n",
      "============================================================\n",
      "Genre: Heavy Metal\n",
      "\n",
      "Lyrics: Lyrics: M.T, M.S., F.M.:\n",
      "I'm the one that's got you to be mine\n",
      "Don't look at me like a woman without my name\n",
      "That's why I've given it all away\n",
      "You're not my mother\n",
      "But I see what you have here, yeah, yeah\n",
      "My love is more than just for your good luck\n",
      "You are not my sister\n",
      "What will change in this life?\n",
      "The future of mankind depends on these rules\n",
      "How we make things work out, how our dreams get better\n",
      "\n",
      "Oh, oh, and behold\n",
      "And where should I start?\n",
      "When am I alone with you?\n",
      "When is I alone with you?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Genre: Heavy Metal\\n\\nLyrics:\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        do_sample=True,\n",
    "        max_length=512,\n",
    "        top_p=0.9,\n",
    "        top_k=50,\n",
    "        temperature=0.9,\n",
    "        repetition_penalty=1.1,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        num_return_sequences=2,\n",
    "    )\n",
    "for i, output in enumerate(outputs, 1):\n",
    "    text = tokenizer.decode(output, skip_special_tokens=True)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SAMPLE {i}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976b583b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
