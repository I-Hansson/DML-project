{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f91c8a46",
   "metadata": {},
   "source": [
    "## First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44d06b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast, GPT2Config\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split, RandomSampler, SequentialSampler\n",
    "\n",
    "\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab60217",
   "metadata": {},
   "source": [
    "Load our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "630791ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 39,415 songs\n",
      "\n",
      "Columns: ['genre', 'lyrics', 'token_count', 'formatted_text']\n",
      "\n",
      "First row preview:\n",
      "genre                                                           Pop\n",
      "lyrics            I feel so unsure\\nAs I take your hand and lead...\n",
      "token_count                                                     400\n",
      "formatted_text    Genre: Pop\\n\\nI feel so unsure\\nAs I take your...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(os.getcwd()).parent / 'data'\n",
    "\n",
    "df = pd.read_csv(f'{data_path}/lyrics_filtered_768tokens.csv')\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(df):,} songs\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst row preview:\")\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86a99295",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "# ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl']\n",
    "model_name = 'gpt2'\n",
    "model_save_path = Path(os.getcwd()).parent / 'models'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b008190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenizer loaded:\n",
      "Vocab size: 50,257\n",
      "EOS token: '<|endoftext|>' (ID: 50256)\n",
      "PAD token: '<|endoftext|>' (ID: 50256)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(f\"\\nTokenizer loaded:\")\n",
    "print(f\"Vocab size: {len(tokenizer):,}\")\n",
    "print(f\"EOS token: '{tokenizer.eos_token}' (ID: {tokenizer.eos_token_id})\")\n",
    "print(f\"PAD token: '{tokenizer.pad_token}' (ID: {tokenizer.pad_token_id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8207b623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24efc387",
   "metadata": {},
   "source": [
    "### Custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "247db494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "class LyricsDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, formatted_texts, tokenizer, max_length=768):\n",
    "\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        \n",
    "        print(f\"Pre-tokenizing {len(formatted_texts)} songs...\")\n",
    "        for text in tqdm(formatted_texts):\n",
    "            encodings = tokenizer.encode_plus(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=max_length,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            self.input_ids.append(encodings['input_ids'].squeeze(0))\n",
    "            self.attn_masks.append(encodings['attention_mask'].squeeze(0))\n",
    "        \n",
    "        print(\"Tokenization complete\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attention_mask': self.attn_masks[idx],\n",
    "            'labels': self.input_ids[idx]  # Same as input for LM\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceffa748",
   "metadata": {},
   "source": [
    "init the loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1929b936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-tokenizing 31532 songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31532/31532 [01:52<00:00, 280.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete\n",
      "Pre-tokenizing 3941 songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3941/3941 [00:13<00:00, 295.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete\n",
      "Pre-tokenizing 3942 songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3942/3942 [00:13<00:00, 286.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, temp_df = train_test_split(\n",
    "    df, \n",
    "    test_size=0.2, \n",
    "    stratify=df['genre'],\n",
    "    random_state=6\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, \n",
    "    test_size=0.5, \n",
    "    stratify=temp_df['genre'],\n",
    "    random_state=6\n",
    ")\n",
    "\n",
    "train_dataset = LyricsDataset(train_df['formatted_text'].tolist(), tokenizer, 768)\n",
    "val_dataset = LyricsDataset(val_df['formatted_text'].tolist(), tokenizer, 768)\n",
    "test_dataset = LyricsDataset(test_df['formatted_text'].tolist(), tokenizer, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80b9e73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 31532\n",
      "Sample shapes:\n",
      "  input_ids: torch.Size([768])\n",
      "  attention_mask: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset size: {len(train_dataset)}\")\n",
    "sample = train_dataset[0]\n",
    "print(f\"Sample shapes:\")\n",
    "print(f\"  input_ids: {sample['input_ids'].shape}\")\n",
    "print(f\"  attention_mask: {sample['attention_mask'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cfd594",
   "metadata": {},
   "source": [
    "Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53e06975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 7883\n",
      "Val batches: 986\n",
      "Test batches: 986\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE = 4\n",
    "MAX_LENGTH = 768\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,       # Don't shuffle validation\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39cf8f2",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9af42500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, optimizer, scheduler, train_loader, device, epoch, num_epochs):\n",
    "    epoch_train_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} (Training)\")\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} (Training)\"):\n",
    "            try:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=input_ids\n",
    "                )\n",
    "                loss = outputs.loss\n",
    "                epoch_train_loss += loss.item()\n",
    "\n",
    "                # Backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                progress_bar.set_postfix({'train_loss': loss.item()})\n",
    "            \n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error in training batch: {e}\")\n",
    "                raise\n",
    "    return epoch_train_loss\n",
    "\n",
    "def train_gpt2_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    num_epochs=3,\n",
    "    patience=2\n",
    "    ):\n",
    "    os.makedirs(\"./models\", exist_ok=True)\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        model.train()\n",
    "\n",
    "\n",
    "        epoch_train_loss = train_loop(model, optimizer, scheduler, train_loader, device, epoch, num_epochs)\n",
    "        \n",
    "        avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} - Avg Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} (Validation)\"):\n",
    "                try:\n",
    "                    input_ids = batch['input_ids'].to(device)\n",
    "                    attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "                    outputs = model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=input_ids\n",
    "                    )\n",
    "                    epoch_val_loss += outputs.loss.item()\n",
    "                \n",
    "                except RuntimeError as e:\n",
    "                    print(f\"Error in validation batch: {e}\")\n",
    "                    raise\n",
    "\n",
    "        avg_val_loss = epoch_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}: Avg Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss - 0.01:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), \"./models/best_gpt2_model.pt\")\n",
    "            print(f'Saved best model checkpoint: epoch {epoch + 1}')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Patience counter: {patience_counter}/{patience}\")\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered after epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "    return model, train_losses, val_losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ab3dbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "LEARNING_RATE = 5e-5      # Standard for fine-tuning\n",
    "NUM_EPOCHS = 3            # Start with 3, can increase if needed\n",
    "WARMUP_STEPS = 500        # Gradual learning rate increase\n",
    "\n",
    "# Model\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model = model.to(device)\n",
    "# Optimizer - AdamW is standard for transformers\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Calculate total training steps\n",
    "total_steps = len(train_loader) * NUM_EPOCHS\n",
    "\n",
    "# Learning rate scheduler with warmup\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=WARMUP_STEPS,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f326ac27",
   "metadata": {},
   "source": [
    "## Test with small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f031a304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-tokenizing 8 songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 177.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete\n",
      "Pre-tokenizing 2 songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 322.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "small_ete_test = df[0:10]\n",
    "small_train_df, small_val_df = train_test_split(\n",
    "    small_ete_test, \n",
    "    test_size=0.2, \n",
    "    stratify=small_ete_test['genre'],\n",
    "    random_state=6\n",
    ")\n",
    "small_train_dataset = LyricsDataset(small_train_df['formatted_text'].tolist(), tokenizer, 768)\n",
    "small_val_dataset = LyricsDataset(small_val_df['formatted_text'].tolist(), tokenizer, 768)\n",
    "\n",
    "small_train_loader = DataLoader(\n",
    "    small_train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "small_val_loader = DataLoader(\n",
    "    small_val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ef85da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 (Training):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model, train_losses, val_losses = train_gpt2_model(model, small_train_loader, small_val_loader, 'cpu', optimizer, scheduler, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ce7854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
