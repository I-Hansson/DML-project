{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f91c8a46",
   "metadata": {},
   "source": [
    "## First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44d06b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast, GPT2Config\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split, RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab60217",
   "metadata": {},
   "source": [
    "Load our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "630791ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 38,792 songs\n",
      "\n",
      "Columns: ['genre', 'lyrics', 'token_count', 'formatted_text']\n",
      "\n",
      "First row preview:\n",
      "genre                                                           Pop\n",
      "lyrics            I feel so unsure\\r\\nAs I take your hand and le...\n",
      "token_count                                                     457\n",
      "formatted_text    Genre: Pop\\n\\nI feel so unsure\\r\\nAs I take yo...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(os.getcwd()).parent / 'data'\n",
    "\n",
    "df = pd.read_csv(f'{data_path}/lyrics_filtered_768tokens.csv')\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(df):,} songs\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst row preview:\")\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86a99295",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "# ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl']\n",
    "model_name = 'gpt2'\n",
    "model_save_path = Path(os.getcwd()).parent / 'models'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b008190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenizer loaded:\n",
      "Vocab size: 50,257\n",
      "EOS token: '<|endoftext|>' (ID: 50256)\n",
      "PAD token: '<|endoftext|>' (ID: 50256)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(f\"\\nTokenizer loaded:\")\n",
    "print(f\"Vocab size: {len(tokenizer):,}\")\n",
    "print(f\"EOS token: '{tokenizer.eos_token}' (ID: {tokenizer.eos_token_id})\")\n",
    "print(f\"PAD token: '{tokenizer.pad_token}' (ID: {tokenizer.pad_token_id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24efc387",
   "metadata": {},
   "source": [
    "### Custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "247db494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "class LyricsDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, formatted_texts, tokenizer, max_length=768):\n",
    "\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        \n",
    "        print(f\"Pre-tokenizing {len(formatted_texts)} songs...\")\n",
    "        for text in tqdm(formatted_texts):\n",
    "            encodings = tokenizer.encode_plus(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=max_length,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            self.input_ids.append(encodings['input_ids'].squeeze(0))\n",
    "            self.attn_masks.append(encodings['attention_mask'].squeeze(0))\n",
    "        \n",
    "        print(\"Tokenization complete\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attention_mask': self.attn_masks[idx],\n",
    "            'labels': self.input_ids[idx]  # Same as input for LM\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceffa748",
   "metadata": {},
   "source": [
    "init the loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1929b936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-tokenizing 31033 songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31033/31033 [00:56<00:00, 547.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete\n",
      "Pre-tokenizing 3879 songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3879/3879 [00:06<00:00, 627.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete\n",
      "Pre-tokenizing 3880 songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3880/3880 [00:06<00:00, 627.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_df, temp_df = train_test_split(\n",
    "    df, \n",
    "    test_size=0.2, \n",
    "    stratify=df['genre'],\n",
    "    random_state=6\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, \n",
    "    test_size=0.5, \n",
    "    stratify=temp_df['genre'],\n",
    "    random_state=6\n",
    ")\n",
    "\n",
    "train_dataset = LyricsDataset(train_df['formatted_text'].tolist(), tokenizer, 768)\n",
    "val_dataset = LyricsDataset(val_df['formatted_text'].tolist(), tokenizer, 768)\n",
    "test_dataset = LyricsDataset(test_df['formatted_text'].tolist(), tokenizer, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80b9e73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 31033\n",
      "Sample shapes:\n",
      "  input_ids: torch.Size([768])\n",
      "  attention_mask: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset size: {len(train_dataset)}\")\n",
    "sample = train_dataset[0]\n",
    "print(f\"Sample shapes:\")\n",
    "print(f\"  input_ids: {sample['input_ids'].shape}\")\n",
    "print(f\"  attention_mask: {sample['attention_mask'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cfd594",
   "metadata": {},
   "source": [
    "Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaf9fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE = 1\n",
    "MAX_LENGTH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53e06975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 31033\n",
      "Val batches: 3879\n",
      "Test batches: 3880\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,       # Don't shuffle validation\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d9dd5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-tokenizing 8 songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 244.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete\n",
      "Pre-tokenizing 2 songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 175.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "small_ete_test = df[0:10]\n",
    "small_train_df, small_val_df = train_test_split(\n",
    "    small_ete_test, \n",
    "    test_size=0.2, \n",
    "    stratify=small_ete_test['genre'],\n",
    "    random_state=6\n",
    ")\n",
    "small_train_dataset = LyricsDataset(small_train_df['formatted_text'].tolist(), tokenizer, 768)\n",
    "small_val_dataset = LyricsDataset(small_val_df['formatted_text'].tolist(), tokenizer, 768)\n",
    "\n",
    "small_train_loader = DataLoader(\n",
    "    small_train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "small_val_loader = DataLoader(\n",
    "    small_val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39cf8f2",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9af42500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, optimizer, scheduler, train_loader, device, epoch, num_epochs):\n",
    "    epoch_train_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} (Training)\")\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} (Training)\"):\n",
    "            try:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=input_ids\n",
    "                )\n",
    "                loss = outputs.loss\n",
    "                epoch_train_loss += loss.item()\n",
    "\n",
    "                # Backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                progress_bar.set_postfix({'train_loss': loss.item()})\n",
    "            \n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error in training batch: {e}\")\n",
    "                raise\n",
    "    return epoch_train_loss\n",
    "\n",
    "def train_gpt2_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    num_epochs=3,\n",
    "    patience=2\n",
    "    ):\n",
    "    os.makedirs(\"./models\", exist_ok=True)\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        model.train()\n",
    "\n",
    "\n",
    "        epoch_train_loss = train_loop(model, optimizer, scheduler, train_loader, device, epoch, num_epochs)\n",
    "        \n",
    "        avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} - Avg Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} (Validation)\"):\n",
    "                try:\n",
    "                    input_ids = batch['input_ids'].to(device)\n",
    "                    attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "                    outputs = model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=input_ids\n",
    "                    )\n",
    "                    epoch_val_loss += outputs.loss.item()\n",
    "                \n",
    "                except RuntimeError as e:\n",
    "                    print(f\"Error in validation batch: {e}\")\n",
    "                    raise\n",
    "\n",
    "        avg_val_loss = epoch_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}: Avg Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss - 0.01:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), \"./models/best_gpt2_model.pt\")\n",
    "            print(f'Saved best model checkpoint: epoch {epoch + 1}')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Patience counter: {patience_counter}/{patience}\")\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered after epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "    return model, train_losses, val_losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ab3dbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "LEARNING_RATE = 5e-5      # Standard for fine-tuning\n",
    "NUM_EPOCHS = 1          # Start with 3, can increase if needed\n",
    "WARMUP_STEPS = 500        # Gradual learning rate increase\n",
    "\n",
    "# Model\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model = model.to(device)\n",
    "# Optimizer - AdamW is standard for transformers\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Calculate total training steps\n",
    "total_steps = len(small_train_loader) * NUM_EPOCHS\n",
    "\n",
    "# Learning rate scheduler with warmup\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=WARMUP_STEPS,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f326ac27",
   "metadata": {},
   "source": [
    "## Test with small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49ef85da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 (Training): 100%|██████████| 8/8 [00:50<00:00,  6.36s/it]oss=5.93]\n",
      "Epoch 1/5 (Training):   0%|          | 0/8 [00:50<?, ?it/s, train_loss=5.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Avg Training Loss: 8.3274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 (Validation): 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: Avg Validation Loss: 10.0561\n",
      "Saved best model checkpoint: epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 (Training): 100%|██████████| 8/8 [00:50<00:00,  6.28s/it]oss=8.28]\n",
      "Epoch 2/5 (Training):   0%|          | 0/8 [00:50<?, ?it/s, train_loss=8.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Avg Training Loss: 8.1021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 (Validation): 100%|██████████| 2/2 [00:04<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: Avg Validation Loss: 9.6078\n",
      "Saved best model checkpoint: epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 (Training): 100%|██████████| 8/8 [00:50<00:00,  6.31s/it]oss=7.53]\n",
      "Epoch 3/5 (Training):   0%|          | 0/8 [00:50<?, ?it/s, train_loss=7.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Avg Training Loss: 7.5502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 (Validation): 100%|██████████| 2/2 [00:04<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: Avg Validation Loss: 8.7717\n",
      "Saved best model checkpoint: epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 (Training): 100%|██████████| 8/8 [00:49<00:00,  6.22s/it]oss=6.45]\n",
      "Epoch 4/5 (Training):   0%|          | 0/8 [00:49<?, ?it/s, train_loss=6.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Avg Training Loss: 6.5246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 (Validation): 100%|██████████| 2/2 [00:04<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: Avg Validation Loss: 7.3489\n",
      "Saved best model checkpoint: epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 (Training): 100%|██████████| 8/8 [00:52<00:00,  6.52s/it]oss=4.8] \n",
      "Epoch 5/5 (Training):   0%|          | 0/8 [00:52<?, ?it/s, train_loss=4.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Avg Training Loss: 5.2347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 (Validation): 100%|██████████| 2/2 [00:04<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: Avg Validation Loss: 5.3797\n",
      "Saved best model checkpoint: epoch 5\n"
     ]
    }
   ],
   "source": [
    "model, train_losses, val_losses = train_gpt2_model(model, small_train_loader, small_val_loader, 'cpu', optimizer, scheduler, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44ce7854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Presenting Results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_curves(train_losses, val_losses):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.plot(epochs, train_losses, label='Training Loss')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss over Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_curves(train_losses, val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9df8105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on Test Set:   3%|▎         | 120/3880 [02:41<1:24:08,  1.34s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Test Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_test_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m avg_test_loss\n\u001b[1;32m---> 37\u001b[0m avg_test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal Test Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_test_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Calculate Perplexity\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 23\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, test_loader, device)\u001b[0m\n\u001b[0;32m     20\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     21\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 23\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem()     \n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\jonte\\Documents\\GitHub\\DML-project\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jonte\\Documents\\GitHub\\DML-project\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jonte\\Documents\\GitHub\\DML-project\\.venv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1271\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1265\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1267\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1269\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1271\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1278\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1281\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1282\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1286\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jonte\\Documents\\GitHub\\DML-project\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jonte\\Documents\\GitHub\\DML-project\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jonte\\Documents\\GitHub\\DML-project\\.venv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1132\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1121\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m   1122\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1129\u001b[0m         output_attentions,\n\u001b[0;32m   1130\u001b[0m     )\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jonte\\Documents\\GitHub\\DML-project\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jonte\\Documents\\GitHub\\DML-project\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jonte\\Documents\\GitHub\\DML-project\\.venv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:615\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    613\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m    614\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(hidden_states)\n\u001b[1;32m--> 615\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    623\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[0;32m    624\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[1;32mc:\\Users\\jonte\\Documents\\GitHub\\DML-project\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jonte\\Documents\\GitHub\\DML-project\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jonte\\Documents\\GitHub\\DML-project\\.venv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:559\u001b[0m, in \u001b[0;36mGPT2SdpaAttention.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    556\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim)\n\u001b[0;32m    558\u001b[0m \u001b[38;5;66;03m# Final projection\u001b[39;00m\n\u001b[1;32m--> 559\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    560\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresid_dropout(attn_output)\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, present, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jonte\\Documents\\GitHub\\DML-project\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jonte\\Documents\\GitHub\\DML-project\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jonte\\Documents\\GitHub\\DML-project\\.venv\\lib\\site-packages\\transformers\\pytorch_utils.py:111\u001b[0m, in \u001b[0;36mConv1D.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    110\u001b[0m     size_out \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnf,)\n\u001b[1;32m--> 111\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddmm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(size_out)\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
    "\n",
    "state_dict = torch.load(\"./models/disitl_gpt2_small_data_4k.pt\", map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating on Test Set\"):\n",
    "            try:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=input_ids\n",
    "                )\n",
    "                total_loss += outputs.loss.item()     \n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error in test batch: {e}\")\n",
    "                raise\n",
    "\n",
    "    avg_test_loss = total_loss / len(test_loader)\n",
    "    print(f\"Average Test Loss: {avg_test_loss:.4f}\")\n",
    "    return avg_test_loss\n",
    "\n",
    "avg_test_loss = evaluate_model(model, test_loader, device)\n",
    "print(f\"Final Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "# Calculate Perplexity\n",
    "\n",
    "perplexity = math.exp(avg_test_loss)\n",
    "print(f\"Final Test Perplexity: {perplexity:.2f}\")\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9413bc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vs Output embedding similarity: 0.8000813722610474\n"
     ]
    }
   ],
   "source": [
    "# GENERATE SAMPLE LYRICS\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
    "\n",
    "state_dict = torch.load(\"./models/disitl_gpt2_small_data_4k.pt\", map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "\n",
    "prompt = \"Genre: \\nLyrics:\\n\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        do_sample=True,\n",
    "        max_length=200,\n",
    "        temperature=0.9,\n",
    "        top_k=50,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.1,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "embedding_layer = model.get_input_embeddings()\n",
    "\n",
    "\n",
    "\n",
    "input_emb = embedding_layer(input_ids)       # shape: [1, seq_len_in, hidden_dim]\n",
    "output_emb = embedding_layer(output_ids)     # shape: [1, seq_len_out, hidden_dim]\n",
    "\n",
    "\n",
    "input_emb_mean = input_emb.mean(dim=1).squeeze(0)\n",
    "output_emb_mean = output_emb.mean(dim=1).squeeze(0)\n",
    "\n",
    "\n",
    "cos_sim = torch.nn.functional.cosine_similarity(input_emb_mean, output_emb_mean, dim=0)\n",
    "print(\"Input vs Output embedding similarity:\", cos_sim.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc530f50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml-project (3.10.19)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
