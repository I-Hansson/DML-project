{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f98896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import GPT2Tokenizer\n",
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "24726d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/isachansson/DML-project/notebooks/models/gpt2_retrained_good_split.pt\n"
     ]
    }
   ],
   "source": [
    "model_path = Path.cwd() / \"models\" / \"gpt2_retrained_good_split.pt\"\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4fa404d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model_name = \"distilgpt2\"\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd476c7",
   "metadata": {},
   "source": [
    "## Get genereated songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f9885b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Heavy Metal': 'Genre: Heavy Metal,\\n\\n\\n\"I am one with the dream of you.\"\\nHe\\'s a demon and no fool.\\n\\nI\\'m searching for someone to blame.\\nThat\\'s all I really want.\\n\\nI feel something cold inside.\\nI never know what it is that we do not understand.\\nWe are alone in this cage.\\nIn this cage, we will stand tall against each others...\\n\\nAnd now I have my dreams fulfilled -\\nThrough dreams we shall survive!\\nTo see their face as they come alive again.\\nMy life has been chosen by god.\\n\\nI don\\'t think about love nor any other good things\\nIt\\'s just like when I was born.\\n\\nI can\\'t even remember how much time ago.\\nNo more tears or hate so easily.\\nYou\\'re always there on my mind at the end of the day.\\n\\nI\\'m searching for someone to blame.\\nThat\\'s all I really want.\\n\\nI feel something cold inside.\\nI never know what it is that we do not understand.\\nWe are alone in this cage.\\nIn this cage, we will stand tall against each others...',\n",
       " 'Pop': 'Genre: Pop,\\n\\n\\nOh yeah!\\n(yeah!)\\nI heard you say that I love you\\nYeah, you know how much we\\'ve been missing in this life. You\\'re so right here at the front door, where all the light is on, and it\\'s gonna change your mind just a little bit for the first time.. Oh yeah!\\nLet me be honest with you... ohhhhhh (ohhh)\\nBaby baby let me show ya my heart to ya girl babe\\nSo tell me what do you mean by saying \\'cause nothing else can compare me\\nYou are my man but everytime i stop feeling like you don\\'t really care if he gets there tonight or tomorrow\\nThen maybe when I think about someone new, then they call him \"baby\" who am I? Yeah-huh uh uh huh-huh (ohhhhhh)\\nAnd ask why our love has changed away from us lately\\nMaybe everything changes now anyway\\nCause things should never go too far cause of something gone wrong around these shores. We gotta make sure nobody sees before we close their eyes\\nSometimes people look out from our window looking up at our face - It could be such a big mistake instead\\nBut always keep inside thinking about somebody better',\n",
       " 'Indie': 'Genre: Indie,\\n\\n\\nHey! Hey! I\\'ve been waiting and seeing your face all day long\\nI got no answers from me lately.\\nMy heart feels like it\\'s in the cold with you.\\nAnd when I feel empty inside, I know where to start.\\nSo get on up there as soon as you find out that I am free.\\nWhen I can\\'t breathe anymore, but tonight is not enough.\\nWe\\'re just a little kids together now; we could never be apart.\\n(If I\\'m only one of these three guys)\\nOur world will grow old for us (Oh!)\\nAnd our friends don\\'t care about nothing at all.\\nWhy do we even dream? Why do we sleep? What happened today?\\n\\nWon\\'t ya tell us what was right or wrong?\\nTell us who did it wrong cause I guess they were hurt somehow.\\nNowadays, things seem so different between us.\\nBut maybe if my feelings are ok then this won`t change forever.\\n\\'Cause sometimes I wish something good would happen someday.\\nMaybe tomorrow isn´t always gonna be alright because\\nwe both need some new direction \\'cause nobody ever had anyone else.\\nJust keep telling ourselves \"'}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Genre: Heavy Metal,\\n\\n\",\n",
    "    \"Genre: Indie,\\n\\n\",\n",
    "    \"Genre: Pop,\\n\\n\"\n",
    "]\n",
    "genres = ['Heavy Metal', 'Indie', 'Pop']\n",
    "genreated_songs = {\n",
    "    'Heavy Metal' : '',\n",
    "    'Pop' : '',\n",
    "    'Indie' : ''\n",
    "}\n",
    "for prompt, genre in zip(prompts, genres):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            do_sample=True,\n",
    "            max_new_tokens=250,\n",
    "            min_new_tokens=200,\n",
    "            top_p=0.92,\n",
    "            top_k=50,\n",
    "            temperature=0.9,\n",
    "            repetition_penalty=1.1,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            num_return_sequences=1,\n",
    "        )\n",
    "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    genreated_songs[genre] = text\n",
    "\n",
    "genreated_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ddfb9b",
   "metadata": {},
   "source": [
    "### Geta  random song from the data one for each genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ff016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre\n",
      "Heavy Metal    13378\n",
      "Pop            13128\n",
      "Indie          12909\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(os.getcwd()).parent / 'data'\n",
    "df = pd.read_csv(f'{data_path}/lyrics_filtered_768tokens.csv')\n",
    "\n",
    "print(df['genre'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe6af2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Pop  Indie  Heavy Metal\n",
      "Gen Pop          0.445  0.343        0.259\n",
      "Gen Indie        0.352  0.310        0.285\n",
      "Gen Heavy Metal  0.395  0.381        0.401\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sampled_real_songs = {}\n",
    "\n",
    "for genre in ['Pop', 'Indie', 'Heavy Metal']:\n",
    "    subset = df[df['genre'] == genre]\n",
    "    samples = subset.sample(30, random_state=6)\n",
    "    sampled_real_songs[genre] = samples['lyrics'].tolist()\n",
    "    \n",
    "semantic_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "genres = ['Pop', 'Indie', 'Heavy Metal']\n",
    "semantic_sim_matrix = np.zeros((len(genres), len(genres)))\n",
    "\n",
    "for i, gen_g in enumerate(genres):\n",
    "\n",
    "    v_gen = torch.tensor(semantic_model.encode(genreated_songs[gen_g], convert_to_numpy=True))\n",
    "    v_gen = v_gen.unsqueeze(0)  \n",
    "    \n",
    "    for j, real_g in enumerate(genres):\n",
    "        sims = []\n",
    "        for real_song in sampled_real_songs[real_g]:\n",
    "            v_real = torch.tensor(semantic_model.encode(real_song, convert_to_numpy=True))\n",
    "            v_real = v_real.unsqueeze(0)\n",
    "            sim = cosine_similarity(v_gen, v_real, dim=1).item()\n",
    "            sims.append(sim)\n",
    "        semantic_sim_matrix[i, j] = np.mean(sims)\n",
    "\n",
    "\n",
    "df_sem = pd.DataFrame(semantic_sim_matrix, index=[f\"Gen {g}\" for g in genres], columns=genres)\n",
    "print(df_sem.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "341c48d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Genre: Heavy Metal,\n",
      "\n",
      "\n",
      "\"I am one with the dream of you.\"\n",
      "He's a demon and no fool.\n",
      "\n",
      "I'm searching for someone to blame.\n",
      "That's all I really want.\n",
      "\n",
      "I feel something cold inside.\n",
      "I never know what it is that we do not understand.\n",
      "We are alone in this cage.\n",
      "In this cage, we will stand tall against each others...\n",
      "\n",
      "And now I have my dreams fulfilled -\n",
      "Through dreams we shall survive!\n",
      "To see their face as they come alive again.\n",
      "My life has been chosen by god.\n",
      "\n",
      "I don't think about love nor any other good things\n",
      "It's just like when I was born.\n",
      "\n",
      "I can't even remember how much time ago.\n",
      "No more tears or hate so easily.\n",
      "You're always there on my mind at the end of the day.\n",
      "\n",
      "I'm searching for someone to blame.\n",
      "That's all I really want.\n",
      "\n",
      "I feel something cold inside.\n",
      "I never know what it is that we do not understand.\n",
      "We are alone in this cage.\n",
      "In this cage, we will stand tall against each others...\n",
      "**************************************************\n",
      "Genre: Pop,\n",
      "\n",
      "\n",
      "Oh yeah!\n",
      "(yeah!)\n",
      "I heard you say that I love you\n",
      "Yeah, you know how much we've been missing in this life. You're so right here at the front door, where all the light is on, and it's gonna change your mind just a little bit for the first time.. Oh yeah!\n",
      "Let me be honest with you... ohhhhhh (ohhh)\n",
      "Baby baby let me show ya my heart to ya girl babe\n",
      "So tell me what do you mean by saying 'cause nothing else can compare me\n",
      "You are my man but everytime i stop feeling like you don't really care if he gets there tonight or tomorrow\n",
      "Then maybe when I think about someone new, then they call him \"baby\" who am I? Yeah-huh uh uh huh-huh (ohhhhhh)\n",
      "And ask why our love has changed away from us lately\n",
      "Maybe everything changes now anyway\n",
      "Cause things should never go too far cause of something gone wrong around these shores. We gotta make sure nobody sees before we close their eyes\n",
      "Sometimes people look out from our window looking up at our face - It could be such a big mistake instead\n",
      "But always keep inside thinking about somebody better\n",
      "**************************************************\n",
      "Genre: Indie,\n",
      "\n",
      "\n",
      "Hey! Hey! I've been waiting and seeing your face all day long\n",
      "I got no answers from me lately.\n",
      "My heart feels like it's in the cold with you.\n",
      "And when I feel empty inside, I know where to start.\n",
      "So get on up there as soon as you find out that I am free.\n",
      "When I can't breathe anymore, but tonight is not enough.\n",
      "We're just a little kids together now; we could never be apart.\n",
      "(If I'm only one of these three guys)\n",
      "Our world will grow old for us (Oh!)\n",
      "And our friends don't care about nothing at all.\n",
      "Why do we even dream? Why do we sleep? What happened today?\n",
      "\n",
      "Won't ya tell us what was right or wrong?\n",
      "Tell us who did it wrong cause I guess they were hurt somehow.\n",
      "Nowadays, things seem so different between us.\n",
      "But maybe if my feelings are ok then this won`t change forever.\n",
      "'Cause sometimes I wish something good would happen someday.\n",
      "Maybe tomorrow isn´t always gonna be alright because\n",
      "we both need some new direction 'cause nobody ever had anyone else.\n",
      "Just keep telling ourselves \"\n"
     ]
    }
   ],
   "source": [
    "for value in genreated_songs.values():\n",
    "    print('*' * 50)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ec8cec",
   "metadata": {},
   "source": [
    "## Do the same for the genre model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8c3de314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "base_model.to(device)\n",
    "base_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "37c26bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Heavy Metal': 'genre: Heavy Metal,\\n\\n\\nThe next game in the series will be an RPG with a lot of possibilities for how to create new characters and story that is quite unique. As players become more familiar with what they are doing from previous games (like Persona 4) some things may change - such as bringing up character names or having various types of items on screen at once if you have already completed one quest while being level 50 (it\\'s not clear yet but this idea probably won\\'t make it through until I see my own prototype).I hope anyone interested can keep checking out other projects around the world including \"Majima Hachi\" because there are so many different ideas floating around these topics throughout The Legend of Zelda World.Thanks!You\\'re logged off Login | Sign Up Log In-By :\\nA group of developers gathered their creativity into something special called Final Fantasy XIV, which has been releasing since May 2015. It consists primarily of three elements:Character creation by combining your gameplay mechanics with those of another player;Fantasy XIV takes place sometime between November 6 and 10th 2017 where events begin each day during development cycle and allows both teams to continue building content without interruption.* This means we\\'ll try to do everything possible within our control over any topic(s), no',\n",
       " 'Pop': 'genre: Pop,\\n\\n\\n“Tropics or other genre-specific features that are not included in this FAQ will cause your game to fail on the Internet. These feature can be disabled by default and cannot be activated without a password (such as OpenPGP) If you use these methods before submitting an application for review please contact us at www...theforum.org/topic/526699 The \"Pop\" list is full of all possible sources of information about what type of content it could provide under Microsoft\\'s Terms of Service; however, only those articles containing such titles should have been approved prior to submission date.\"http://www..thisforum.com/forum/topic=25309428 Please include any references regarding where some games might appear if there were no relevant software specific to them.[1] http\\xa0does not constitute “all claims required[/1]. ~~~~~~~~~~~~~~~~~~~~~~~ \\xa0 - Gameplay Review All About Games **If you\\'ve downloaded anything from here they\\'ll give out their best reviews! They\\'re very good but after reading my previous blog post I\\'m almost convinced we shouldn\\'t let one get too carried away with gaming experience over again. So just remember that nothing seems to work perfectly when reviewing something like Dragon Age 4,',\n",
       " 'Indie': 'genre: Indie,\\n\\n\\nWhat the fuck does it look like when you get a lot of money from indie games? Well what\\'s that about? I\\'m just saying for an overview! If there\\'s any way to make sense of this stuff, take note. The average amount of funding available is around $1,200 dollars (at least on Kickstarter). That means roughly one-third goes to publishers who want to keep their product or other high quality titles out of sales so they don\\'t have to spend all those years looking at \"what else\" and making them sell.\" They are also very expensive,\" he said. But most gamers feel pretty much free not to pay more than some kind of cash game where people can only buy whatever if they really needed something new because then why do these low price items be considered good value?\"It gets interesting though because no company has tried quite as hard as Activision in terms by offering similar things every time someone makes fun of others - either through being awesome with anything made during development without getting paid based off of nothing but having been involved personally or indirectly; instead, studios choose which thing works best according to how successful consumers think...to go along with traditional franchises such Asphalt 8, Assassin\\'s Creed Syndicate 2, etc. In my'}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"genre: Heavy Metal,\\n\\n\",\n",
    "    \"genre: Indie,\\n\\n\",\n",
    "    \"genre: Pop,\\n\\n\"\n",
    "]\n",
    "genres = ['Heavy Metal', 'Indie', 'Pop']\n",
    "baseline_genreated_songs = {\n",
    "    'Heavy Metal' : '',\n",
    "    'Pop' : '',\n",
    "    'Indie' : ''\n",
    "}\n",
    "for prompt, genre in zip(prompts, genres):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.inference_mode():\n",
    "        outputs = base_model.generate(\n",
    "            input_ids,\n",
    "            do_sample=True,\n",
    "            max_new_tokens=250,\n",
    "            min_new_tokens=200,\n",
    "            top_p=0.92,\n",
    "            top_k=50,\n",
    "            temperature=0.9,\n",
    "            repetition_penalty=1.1,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            num_return_sequences=1,\n",
    "        )\n",
    "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    baseline_genreated_songs[genre] = text\n",
    "\n",
    "baseline_genreated_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9e91763b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "genre: Heavy Metal,\n",
      "\n",
      "\n",
      "The next game in the series will be an RPG with a lot of possibilities for how to create new characters and story that is quite unique. As players become more familiar with what they are doing from previous games (like Persona 4) some things may change - such as bringing up character names or having various types of items on screen at once if you have already completed one quest while being level 50 (it's not clear yet but this idea probably won't make it through until I see my own prototype).I hope anyone interested can keep checking out other projects around the world including \"Majima Hachi\" because there are so many different ideas floating around these topics throughout The Legend of Zelda World.Thanks!You're logged off Login | Sign Up Log In-By :\n",
      "A group of developers gathered their creativity into something special called Final Fantasy XIV, which has been releasing since May 2015. It consists primarily of three elements:Character creation by combining your gameplay mechanics with those of another player;Fantasy XIV takes place sometime between November 6 and 10th 2017 where events begin each day during development cycle and allows both teams to continue building content without interruption.* This means we'll try to do everything possible within our control over any topic(s), no\n",
      "**************************************************\n",
      "genre: Pop,\n",
      "\n",
      "\n",
      "“Tropics or other genre-specific features that are not included in this FAQ will cause your game to fail on the Internet. These feature can be disabled by default and cannot be activated without a password (such as OpenPGP) If you use these methods before submitting an application for review please contact us at www...theforum.org/topic/526699 The \"Pop\" list is full of all possible sources of information about what type of content it could provide under Microsoft's Terms of Service; however, only those articles containing such titles should have been approved prior to submission date.\"http://www..thisforum.com/forum/topic=25309428 Please include any references regarding where some games might appear if there were no relevant software specific to them.[1] http does not constitute “all claims required[/1]. ~~~~~~~~~~~~~~~~~~~~~~~   - Gameplay Review All About Games **If you've downloaded anything from here they'll give out their best reviews! They're very good but after reading my previous blog post I'm almost convinced we shouldn't let one get too carried away with gaming experience over again. So just remember that nothing seems to work perfectly when reviewing something like Dragon Age 4,\n",
      "**************************************************\n",
      "genre: Indie,\n",
      "\n",
      "\n",
      "What the fuck does it look like when you get a lot of money from indie games? Well what's that about? I'm just saying for an overview! If there's any way to make sense of this stuff, take note. The average amount of funding available is around $1,200 dollars (at least on Kickstarter). That means roughly one-third goes to publishers who want to keep their product or other high quality titles out of sales so they don't have to spend all those years looking at \"what else\" and making them sell.\" They are also very expensive,\" he said. But most gamers feel pretty much free not to pay more than some kind of cash game where people can only buy whatever if they really needed something new because then why do these low price items be considered good value?\"It gets interesting though because no company has tried quite as hard as Activision in terms by offering similar things every time someone makes fun of others - either through being awesome with anything made during development without getting paid based off of nothing but having been involved personally or indirectly; instead, studios choose which thing works best according to how successful consumers think...to go along with traditional franchises such Asphalt 8, Assassin's Creed Syndicate 2, etc. In my\n"
     ]
    }
   ],
   "source": [
    "for value in baseline_genreated_songs.values():\n",
    "    print('*' * 50)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5905b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Pop  Indie  Heavy Metal\n",
      "Gen Pop          0.198  0.179        0.170\n",
      "Gen Indie        0.236  0.222        0.202\n",
      "Gen Heavy Metal  0.225  0.181        0.192\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sampled_real_songs = {}\n",
    "\n",
    "for genre in ['Pop', 'Indie', 'Heavy Metal']:\n",
    "    subset = df[df['genre'] == genre]\n",
    "    samples = subset.sample(50, random_state=6)\n",
    "    sampled_real_songs[genre] = samples['lyrics'].tolist()\n",
    "    \n",
    "\n",
    "genres = ['Pop', 'Indie', 'Heavy Metal']\n",
    "semantic_sim_matrix = np.zeros((len(genres), len(genres)))\n",
    "\n",
    "for i, gen_g in enumerate(genres):\n",
    "\n",
    "    v_gen = torch.tensor(semantic_model.encode(baseline_genreated_songs[gen_g], convert_to_numpy=True))\n",
    "    v_gen = v_gen.unsqueeze(0)  \n",
    "    \n",
    "    for j, real_g in enumerate(genres):\n",
    "        sims = []\n",
    "        for real_song in sampled_real_songs[real_g]:\n",
    "            v_real = torch.tensor(semantic_model.encode(real_song, convert_to_numpy=True))\n",
    "            v_real = v_real.unsqueeze(0)\n",
    "            sim = cosine_similarity(v_gen, v_real, dim=1).item()\n",
    "            sims.append(sim)\n",
    "        semantic_sim_matrix[i, j] = np.mean(sims)\n",
    "\n",
    "\n",
    "df_sem = pd.DataFrame(semantic_sim_matrix, index=[f\"Gen {g}\" for g in genres], columns=genres)\n",
    "print(df_sem.round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c11fedb",
   "metadata": {},
   "source": [
    "## Calculate perplexity score by \n",
    "\n",
    "Calculate the perplexity by calulating the loss over the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab327548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same dataset as in genre_model\n",
    "class LyricsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, formatted_texts, tokenizer, max_length=768):\n",
    "\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        \n",
    "        print(f\"Pre-tokenizing {len(formatted_texts)} songs...\")\n",
    "        for text in tqdm(formatted_texts):\n",
    "            encodings = tokenizer.encode_plus(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=max_length,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            self.input_ids.append(encodings['input_ids'].squeeze(0))\n",
    "            self.attn_masks.append(encodings['attention_mask'].squeeze(0))\n",
    "        \n",
    "        print(\"Tokenization complete\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attention_mask': self.attn_masks[idx],\n",
    "            'labels': self.input_ids[idx]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2428bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loop(model, val_df, tokenizer, max_length=768, batch_size=8, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "\n",
    "    val_dataset = LyricsDataset(val_df['formatted_text'].tolist(), tokenizer, max_length=max_length)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    batch_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc=\"Val\")\n",
    "        for batch in progress_bar:\n",
    "            try:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                \n",
    "                batch_loss = outputs.loss.item()\n",
    "                batch_losses.append(batch_loss)\n",
    "\n",
    "                progress_bar.set_postfix({\"Batch Loss\": f\"{batch_loss:.4f}\"})\n",
    "                \n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                raise\n",
    "    \n",
    "    avg_loss = np.mean(batch_losses)\n",
    "    perplexity = np.exp(avg_loss)\n",
    "    \n",
    "    print(f\"Validation completed.Average Loss: {avg_loss:.4f}, Ppl: {perplexity:.4f}\")\n",
    "    \n",
    "    return perplexity\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70ab74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3942\n",
      "Pre-tokenizing 3942 songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3942 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3942/3942 [00:08<00:00, 490.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation (Perplexity): 100%|██████████| 493/493 [01:29<00:00,  5.50it/s, Batch Loss=0.7849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation completed. Average Loss: 0.9534, Perplexity: 2.5946\n",
      "Test PPL: 2.5946287127550067\n",
      "3941\n",
      "Pre-tokenizing 3941 songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3941/3941 [00:07<00:00, 506.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation (Perplexity): 100%|██████████| 493/493 [01:29<00:00,  5.50it/s, Batch Loss=1.0446]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation completed. Average Loss: 0.9707, Perplexity: 2.6398\n",
      "Validation PPL: 2.6397894304066747\n",
      "31532\n",
      "Pre-tokenizing 31532 songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31532/31532 [00:59<00:00, 530.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation (Perplexity): 100%|██████████| 3942/3942 [11:56<00:00,  5.50it/s, Batch Loss=1.0181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation completed. Average Loss: 0.9306, Perplexity: 2.5360\n",
      "Training PPL: 2.535964428234951\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>token_count</th>\n",
       "      <th>formatted_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pop</td>\n",
       "      <td>With music by our side\\nTo break the color lin...</td>\n",
       "      <td>204</td>\n",
       "      <td>Genre: Pop\\n\\nWith music by our side\\nTo break...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pop</td>\n",
       "      <td>In your bed or in your car\\nOn the earth or up...</td>\n",
       "      <td>456</td>\n",
       "      <td>Genre: Pop\\n\\nIn your bed or in your car\\nOn t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pop</td>\n",
       "      <td>(Verse)\\nYou ain't gotta say too much cause I ...</td>\n",
       "      <td>347</td>\n",
       "      <td>Genre: Pop\\n\\n(Verse)\\nYou ain't gotta say too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pop</td>\n",
       "      <td>Someone's drinking all alone\\nSomeone's left t...</td>\n",
       "      <td>147</td>\n",
       "      <td>Genre: Pop\\n\\nSomeone's drinking all alone\\nSo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heavy Metal</td>\n",
       "      <td>hey you, I need a friend, I hope you feel the ...</td>\n",
       "      <td>280</td>\n",
       "      <td>Genre: Heavy Metal\\n\\nhey you, I need a friend...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         genre                                             lyrics  \\\n",
       "0          Pop  With music by our side\\nTo break the color lin...   \n",
       "1          Pop  In your bed or in your car\\nOn the earth or up...   \n",
       "2          Pop  (Verse)\\nYou ain't gotta say too much cause I ...   \n",
       "3          Pop  Someone's drinking all alone\\nSomeone's left t...   \n",
       "4  Heavy Metal  hey you, I need a friend, I hope you feel the ...   \n",
       "\n",
       "   token_count                                     formatted_text  \n",
       "0          204  Genre: Pop\\n\\nWith music by our side\\nTo break...  \n",
       "1          456  Genre: Pop\\n\\nIn your bed or in your car\\nOn t...  \n",
       "2          347  Genre: Pop\\n\\n(Verse)\\nYou ain't gotta say too...  \n",
       "3          147  Genre: Pop\\n\\nSomeone's drinking all alone\\nSo...  \n",
       "4          280  Genre: Heavy Metal\\n\\nhey you, I need a friend...  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in and the data and calculate perplexity\n",
    "\n",
    "test_df = pd.read_csv('./data/test_split.csv')\n",
    "print(len(test_df))\n",
    "test_ppl = validation_loop(model, test_df, tokenizer)\n",
    "print(f\"Test PPL: {test_ppl}\")\n",
    "\n",
    "val_df = pd.read_csv('./data/val_split.csv')\n",
    "print(len(val_df))\n",
    "val_ppl = validation_loop(model, val_df, tokenizer)\n",
    "print(f\"Validation PPL: {val_ppl}\")\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('./data2/train_split.csv')\n",
    "print(len(train_df))\n",
    "train_ppl = validation_loop(model, train_df, tokenizer)\n",
    "print(f\"Training PPL: {train_ppl}\")\n",
    "\n",
    "test_df.head(5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
